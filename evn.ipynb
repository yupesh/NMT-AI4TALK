{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b71da60-dedd-4eac-9bcb-89254b84222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pympi-ling\n",
      "  Downloading pympi_ling-1.70.2-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pympi-ling\n",
      "Successfully installed pympi-ling-1.70.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pympi-ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe22dd4-f93c-4aeb-b108-54a3fe24c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16d4299-e1e2-402c-b7b0-45d6c358c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob     # Import glob to easily loop over files\n",
    "import pympi    # Import pympi to work with elan files\n",
    "import string   # Import string to get the punctuation data\n",
    "from cyrillicToLatin import cyrToIPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fafde89-5ec1-4967-a502-40019ab94f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \n",
    "    if(\"сера\") in string:\n",
    "        print (string)\n",
    "    \n",
    "    a=re.compile(\"<.*?>\")\n",
    "    txt=a.sub('',string)\n",
    "    \n",
    "\n",
    "    \n",
    "    if \"нет в аудио\" in txt:\n",
    "        txt = txt.replace(\"[\",'')\n",
    "        txt = txt.replace(\"]\",'')\n",
    "        txt = txt.replace(\"нет в аудио\",'')\n",
    "    \n",
    "    txt = txt.replace(\"'\",'')\n",
    "    txt = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", txt).lower()\n",
    "    txt = re.sub(r'{[^}]*}','',txt)\n",
    "    \n",
    "    spl = txt.split('/')\n",
    "    if len(spl) > 2:\n",
    "        txt = ''.join((spl[0], spl[-1]))\n",
    "    \n",
    "        \n",
    "    txt = txt.replace('/','')\n",
    "    \n",
    "    \n",
    "    txt = txt.replace('*', '')\n",
    "    txt = txt.replace('\"', '')\n",
    "    txt = txt.replace('«', '')\n",
    "    txt = txt.replace('»', '')\n",
    "    txt = txt.replace('ʼ', '')\n",
    "    txt = txt.replace('—','')\n",
    "    txt = \" \".join(txt.split())\n",
    "    \n",
    "    txt = txt.replace('ˊ','')\n",
    "    txt = txt.replace('ˋ','')\n",
    "#     txt = txt.replace('ң','ӈ')\n",
    "#     txt = txt.replace('i','и')\n",
    "#     txt = txt.replace('j','й')\n",
    "#     txt = txt.replace('l','л')\n",
    "#     txt = txt.replace('w','в')\n",
    "#     txt = txt.replace('џ','')\n",
    "#     txt = txt.replace('ӱ','у')\n",
    "#     txt = txt.replace('ӓ','а̄')\n",
    "#     txt = txt.replace('і','и')\n",
    "#     txt = txt.replace('ӧ','о̄')\n",
    "    txt = txt.replace('ѣ','е')\n",
    "#     txt = txt.replace('йа','я')\n",
    "    \n",
    "#     txt = txt.replace('ӯ','у')\n",
    "#     txt = txt.replace('ы̄','ы')\n",
    "#     txt = txt.replace(\"'\",'')\n",
    "#     txt = txt.replace('x','х')\n",
    "#     txt = txt.replace('c','с')\n",
    "#     txt = txt.replace('e','е')\n",
    "#     txt = txt.replace('y','у')\n",
    "#     txt = txt.replace('u','и')\n",
    "#     txt = txt.replace('o','о')\n",
    "#     txt = txt.replace('p','р')\n",
    "#     txt = txt.replace('a','а')\n",
    "#     txt = txt.replace('k','к')\n",
    "#     txt = txt.replace('n','п')\n",
    "#     txt = txt.replace('s','с')\n",
    "    txt = txt.replace(\"=\",'')\n",
    "    #txt =re.sub(r\"\\d+\", \"\", txt)\n",
    "    txt = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', txt)\n",
    "\n",
    "    #txt = re.sub(r'[^\\w\\s]','',txt)\n",
    "    txt = re.sub(r'[.,\"\\'?:!;]', '', txt)\n",
    "    txt = txt.replace(\"[\",'')\n",
    "    txt = txt.replace(\"]\",'')\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8b39b6-d6c2-467a-a4e5-dd776c1e51ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./evenki-corpus-master/corpus/evenki/eaf/2005_Poligus_Khadonchina_LR2.eaf_new.eaf\n",
      "WARNING!!! ./evenki-corpus-master/corpus/evenki/eaf/Arch_Levedeva_1952_Uchami_Lopoko_Robbery.eaf\n",
      "One of the ortography tiers is not present in the elan file\n",
      "namely: ev. skipping this one...\n"
     ]
    }
   ],
   "source": [
    "# Define some variables for later use\n",
    "corpus_root = './evenki-corpus-master/corpus/evenki/eaf/'\n",
    "\n",
    "#ort_tier_names = ['evCyr', 'rus']\n",
    "ort_tier_names = ['ev', 'rus']\n",
    "\n",
    "# Initialize the frequency dictionary\n",
    "frequency_dict = {}\n",
    "out = {}\n",
    "#corpus = open(\"dataset/evn_corpus.tsv\",\"w\")\n",
    "# Loop over all elan files the corpusroot subdirectory called eaf\n",
    "for file_path in glob.glob('{}/*.eaf'.format(corpus_root)):\n",
    "    #print(file_path)\n",
    "    # Initialize the elan file\n",
    "    eafob = pympi.Elan.Eaf(file_path)\n",
    "    #print(eafob.get_tier_names())\n",
    "    # Loop over all the defined tiers that contain orthography\n",
    "    for ort_tier in ort_tier_names:\n",
    "        # If the tier is not present in the elan file spew an error and\n",
    "        # continue. This is done to avoid possible KeyErrors\n",
    "        if ort_tier not in eafob.get_tier_names():\n",
    "            if ort_tier == \"ev\":\n",
    "                if \"evCyr\" in eafob.get_tier_names():\n",
    "                    for annotation in eafob.get_annotation_data_for_tier(\"evCyr\"):\n",
    "                        if ort_tier not in out:\n",
    "                            out[ort_tier] = [annotation[2]]\n",
    "                        else:\n",
    "                            out[ort_tier].extend([annotation[2]])\n",
    "            print ('WARNING!!!',file_path)\n",
    "            print ('One of the ortography tiers is not present in the elan file')\n",
    "            print ('namely: {}. skipping this one...'.format(ort_tier))\n",
    "        # If the tier is present we can loop through the annotation data\n",
    "        else:\n",
    "            #print(\"one\")\n",
    "            for annotation in eafob.get_annotation_data_for_tier(ort_tier):\n",
    "                if \"Вот умукэ̄н миндӯ бичо̄н ученикив\" in annotation[2]:\n",
    "                    print (file_path)\n",
    "                if ort_tier not in out:\n",
    "                    out[ort_tier] = [annotation[2]]\n",
    "                else:\n",
    "                    out[ort_tier].extend([annotation[2]])\n",
    "                #corpus.write(thiselem+\"\\t\"+nextelem+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66351d49-dfb8-4a4c-81fe-2e0c24bd850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b8ad56e-8856-41a2-9d42-4e26d0e4a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"dataset/evn_corpus.tsv\",\"w\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e4a9ee-f35a-4739-b728-05e000914cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hаӈа̄рил эдо̄тын биhэ, мӯ эдо̄н чургӣдерэ, до̄скӣ нуӈан тар аӈит... сера сера как же это?... нютэт, нютэт.\n",
      "Чтобы не было дыр, чтобы не просочилась вода, он вовнутрь этой самой... сера, сера {имеется в виду русское диалектное название смолы}, как же это? Смолой, смолой.\n",
      "Говорила, что сейчас бисера очень много, только бы заниматься\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i<len(out[\"rus\"]):\n",
    "    if out['ev'][i] != '':\n",
    "        if out['ev'][i][0].isdigit():\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "    # string1 = re.sub(\"^\\s+|\\n|\\r|\\s+$\", '', string1)\n",
    "    # string2 = re.sub(\"^\\s+|\\n|\\r|\\s+$\", '', string2)\n",
    "\n",
    "    \n",
    "\n",
    "    string1 = clean_text(out['ev'][i])\n",
    "    string1 = cyrToIPA(string1)\n",
    "    string2 = clean_text(out['rus'][i])\n",
    "\n",
    "    # if has_latin(string1):\n",
    "    #     i+=1\n",
    "    #     continue\n",
    "    if string1 and string2:\n",
    "        corpus.write(string1+\"\\t\"+string2+\"\\n\")\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc33bee6-cfb8-47d4-b747-f0b5f4ab2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
